{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import darts\n",
    "from darts import TimeSeries\n",
    "from darts.models import ExponentialSmoothing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import httpx\n",
    "import json\n",
    "import sqlite3\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtained from fuzzworks\n",
    "invData = pd.read_csv('../invTypes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMarketPrices(inplace=False):\n",
    "    print('Fetching market prices')\n",
    "    r = httpx.get(\n",
    "        'https://esi.evetech.net/latest/markets/prices/?datasource=tranquility',)\n",
    "    if (r.status_code == 200):\n",
    "        df = pd.read_json(r.text)\n",
    "        df['date'] = dt.datetime.now()\n",
    "        con = sqlite3.connect('../data/data.db')\n",
    "        df.to_sql(con=con, name=\"market_data\", if_exists=\"append\")\n",
    "        con.close()\n",
    "        if (inplace):\n",
    "            return (df)\n",
    "        # cur = con.cursor()\n",
    "        # cur.execute('select * from market_data')\n",
    "        # results = cur.fetchall()\n",
    "        # print(results)\n",
    "    else:\n",
    "        print(f\"Request did not succeed! {r.status_code}\")\n",
    "        rjson = json.loads(r.text)\n",
    "        if (rjson['timeout'] != None or 0):\n",
    "            time.sleep((rjson['timeout']/1000))\n",
    "# getMarketPrices()\n",
    "# adjusted_price, average_price, type_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getItemPrices(id):\n",
    "    # refresh database with new data\n",
    "    getMarketPrices()\n",
    "    con = sqlite3.connect('../data.db')\n",
    "    # df = pd.read_sql_table(table_name='market_data',con=con,parse_dates='date')\n",
    "    # cur = con.cursor()\n",
    "    # cur.execute(\"select * from market_data\")\n",
    "    df = pd.read_sql('select * from market_data', con, parse_dates=['date'])\n",
    "    selected_df = df.loc[df['type_id'] == id]\n",
    "    if (len(selected_df) != 0):\n",
    "        return (selected_df)\n",
    "    else:\n",
    "        print('Sorry, either this is not a valid item id or something went wrong. :P')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getIDInfo(id):\n",
    "    selected_row = invData.loc[invData['typeID'] == id]\n",
    "    return selected_row\n",
    "# getIDInfo(32772)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getIdFromName(name):\n",
    "    # NOTE: This function could be improved with a better search engine\n",
    "    selected_rows = invData[invData['typeName'].str.contains(name, False)]\n",
    "    selected_rows = selected_rows[['typeName', 'typeID']]\n",
    "    return (selected_rows)\n",
    "# getIdFromName('Booster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ValueError: The time index of the provided DataArray is missing the freq attribute, and the frequency could not be directly inferred. This probably comes from inconsistent date frequencies with missing dates. If you know the actual frequency, try setting `fill_missing_dates=True, freq=actual_frequency`. If not, try setting `fill_missing_dates=True, freq=None` to see if a frequency can be inferred.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The time index of the provided DataArray is missing the freq attribute, and the frequency could not be directly inferred. This probably comes from inconsistent date frequencies with missing dates. If you know the actual frequency, try setting `fill_missing_dates=True, freq=actual_frequency`. If not, try setting `fill_missing_dates=True, freq=None` to see if a frequency can be inferred.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m databaseframe \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_sql(\u001b[39m'\u001b[39m\u001b[39mselect * from market_data\u001b[39m\u001b[39m'\u001b[39m, con, parse_dates\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mdate\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m      3\u001b[0m con\u001b[39m.\u001b[39mclose()\n\u001b[1;32m----> 4\u001b[0m series \u001b[39m=\u001b[39m TimeSeries\u001b[39m.\u001b[39;49mfrom_dataframe(df\u001b[39m=\u001b[39;49mdatabaseframe, time_col\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mdate\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      5\u001b[0m train, val \u001b[39m=\u001b[39m series\u001b[39m.\u001b[39msplit_after(\u001b[39m.6\u001b[39m)\n\u001b[0;32m      6\u001b[0m model_es \u001b[39m=\u001b[39m ExponentialSmoothing()\n",
      "File \u001b[1;32mc:\\Users\\Joe\\Desktop\\javis-kamiya-dojo\\EVE-Market-Predictor\\env\\lib\\site-packages\\darts\\timeseries.py:668\u001b[0m, in \u001b[0;36mTimeSeries.from_dataframe\u001b[1;34m(cls, df, time_col, value_cols, fill_missing_dates, freq, fillna_value, static_covariates, hierarchy)\u001b[0m\n\u001b[0;32m    659\u001b[0m     time_index\u001b[39m.\u001b[39mname \u001b[39m=\u001b[39m time_col \u001b[39mif\u001b[39;00m time_col \u001b[39melse\u001b[39;00m DIMS[\u001b[39m0\u001b[39m]\n\u001b[0;32m    661\u001b[0m xa \u001b[39m=\u001b[39m xr\u001b[39m.\u001b[39mDataArray(\n\u001b[0;32m    662\u001b[0m     series_df\u001b[39m.\u001b[39mvalues[:, :, np\u001b[39m.\u001b[39mnewaxis],\n\u001b[0;32m    663\u001b[0m     dims\u001b[39m=\u001b[39m(time_index\u001b[39m.\u001b[39mname,) \u001b[39m+\u001b[39m DIMS[\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m:],\n\u001b[0;32m    664\u001b[0m     coords\u001b[39m=\u001b[39m{time_index\u001b[39m.\u001b[39mname: time_index, DIMS[\u001b[39m1\u001b[39m]: series_df\u001b[39m.\u001b[39mcolumns},\n\u001b[0;32m    665\u001b[0m     attrs\u001b[39m=\u001b[39m{STATIC_COV_TAG: static_covariates, HIERARCHY_TAG: hierarchy},\n\u001b[0;32m    666\u001b[0m )\n\u001b[1;32m--> 668\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mfrom_xarray(\n\u001b[0;32m    669\u001b[0m     xa\u001b[39m=\u001b[39;49mxa,\n\u001b[0;32m    670\u001b[0m     fill_missing_dates\u001b[39m=\u001b[39;49mfill_missing_dates,\n\u001b[0;32m    671\u001b[0m     freq\u001b[39m=\u001b[39;49mfreq,\n\u001b[0;32m    672\u001b[0m     fillna_value\u001b[39m=\u001b[39;49mfillna_value,\n\u001b[0;32m    673\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Joe\\Desktop\\javis-kamiya-dojo\\EVE-Market-Predictor\\env\\lib\\site-packages\\darts\\timeseries.py:412\u001b[0m, in \u001b[0;36mTimeSeries.from_xarray\u001b[1;34m(cls, xa, fill_missing_dates, freq, fillna_value)\u001b[0m\n\u001b[0;32m    408\u001b[0m \u001b[39m# We cast the array to float\u001b[39;00m\n\u001b[0;32m    409\u001b[0m \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39missubdtype(xa_\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39mdtype, np\u001b[39m.\u001b[39mfloat32) \u001b[39mor\u001b[39;00m np\u001b[39m.\u001b[39missubdtype(\n\u001b[0;32m    410\u001b[0m     xa_\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39mdtype, np\u001b[39m.\u001b[39mfloat64\n\u001b[0;32m    411\u001b[0m ):\n\u001b[1;32m--> 412\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m(xa_)\n\u001b[0;32m    413\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    414\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m(xa_\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mfloat64))\n",
      "File \u001b[1;32mc:\\Users\\Joe\\Desktop\\javis-kamiya-dojo\\EVE-Market-Predictor\\env\\lib\\site-packages\\darts\\timeseries.py:170\u001b[0m, in \u001b[0;36mTimeSeries.__init__\u001b[1;34m(self, xa)\u001b[0m\n\u001b[0;32m    162\u001b[0m freq_tmp \u001b[39m=\u001b[39m xa\u001b[39m.\u001b[39mget_index(\n\u001b[0;32m    163\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time_dim\n\u001b[0;32m    164\u001b[0m )\u001b[39m.\u001b[39mfreq  \u001b[39m# store original freq (see bug of sortby() above).\u001b[39;00m\n\u001b[0;32m    165\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_freq: pd\u001b[39m.\u001b[39mDateOffset \u001b[39m=\u001b[39m (\n\u001b[0;32m    166\u001b[0m     freq_tmp\n\u001b[0;32m    167\u001b[0m     \u001b[39mif\u001b[39;00m freq_tmp \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    168\u001b[0m     \u001b[39melse\u001b[39;00m to_offset(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_xa\u001b[39m.\u001b[39mget_index(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time_dim)\u001b[39m.\u001b[39minferred_freq)\n\u001b[0;32m    169\u001b[0m )\n\u001b[1;32m--> 170\u001b[0m raise_if(\n\u001b[0;32m    171\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_freq \u001b[39mis\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    172\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mThe time index of the provided DataArray is missing the freq attribute, and the frequency could \u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[0;32m    173\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mnot be directly inferred. \u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[0;32m    174\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mThis probably comes from inconsistent date frequencies with missing dates. \u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[0;32m    175\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mIf you know the actual frequency, try setting `fill_missing_dates=True, freq=actual_frequency`. \u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[0;32m    176\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mIf not, try setting `fill_missing_dates=True, freq=None` to see if a frequency can be inferred.\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    177\u001b[0m     logger,\n\u001b[0;32m    178\u001b[0m )\n\u001b[0;32m    180\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_freq_str: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_freq\u001b[39m.\u001b[39mfreqstr\n\u001b[0;32m    182\u001b[0m \u001b[39m# reset freq inside the xarray index (see bug of sortby() above).\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Joe\\Desktop\\javis-kamiya-dojo\\EVE-Market-Predictor\\env\\lib\\site-packages\\darts\\logging.py:104\u001b[0m, in \u001b[0;36mraise_if\u001b[1;34m(condition, message, logger)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mraise_if\u001b[39m(\n\u001b[0;32m     82\u001b[0m     condition: \u001b[39mbool\u001b[39m,\n\u001b[0;32m     83\u001b[0m     message: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     84\u001b[0m     logger: logging\u001b[39m.\u001b[39mLogger \u001b[39m=\u001b[39m get_logger(\u001b[39m\"\u001b[39m\u001b[39mmain_logger\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m     85\u001b[0m ):\n\u001b[0;32m     86\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     87\u001b[0m \u001b[39m    Checks provided boolean condition and raises a ValueError if it evaluates to True.\u001b[39;00m\n\u001b[0;32m     88\u001b[0m \u001b[39m    It logs the error to the provided logger before raising it.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[39m        if `condition` is satisfied\u001b[39;00m\n\u001b[0;32m    103\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 104\u001b[0m     raise_if_not(\u001b[39mnot\u001b[39;49;00m condition, message, logger)\n",
      "File \u001b[1;32mc:\\Users\\Joe\\Desktop\\javis-kamiya-dojo\\EVE-Market-Predictor\\env\\lib\\site-packages\\darts\\logging.py:78\u001b[0m, in \u001b[0;36mraise_if_not\u001b[1;34m(condition, message, logger)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m condition:\n\u001b[0;32m     77\u001b[0m     logger\u001b[39m.\u001b[39merror(\u001b[39m\"\u001b[39m\u001b[39mValueError: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m message)\n\u001b[1;32m---> 78\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(message)\n",
      "\u001b[1;31mValueError\u001b[0m: The time index of the provided DataArray is missing the freq attribute, and the frequency could not be directly inferred. This probably comes from inconsistent date frequencies with missing dates. If you know the actual frequency, try setting `fill_missing_dates=True, freq=actual_frequency`. If not, try setting `fill_missing_dates=True, freq=None` to see if a frequency can be inferred."
     ]
    }
   ],
   "source": [
    "def resample_one_minute(df):\n",
    "    # Make sure the dataframe has a datetime index\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "    # Resample the dataframe on one minute intervals\n",
    "    df_resampled = df.resample('1T').mean()\n",
    "    return df_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fix data for forecasting\n",
    "con = sqlite3.connect('../data.db')\n",
    "databaseframe = pd.read_sql(\n",
    "    'select * from market_data', con, parse_dates=['date'])\n",
    "con.close()\n",
    "fixedData = resample_one_minute(databaseframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# con = sqlite3.connect('../data.db')\n",
    "# databaseframe = pd.read_sql('select * from market_data', con, parse_dates=['date'])\n",
    "# con.close()\n",
    "series = TimeSeries.from_dataframe(df=fixedData, time_col='date')\n",
    "train, val = series.split_after(.6)\n",
    "model_es = ExponentialSmoothing()\n",
    "model_es.fit(train)\n",
    "probabilistic_forecast = model_es.predict(len(val), num_samples=500)\n",
    "\n",
    "series.plot(label=\"actual\")\n",
    "probabilistic_forecast.plot(label=\"probabilistic forecast\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 | packaged by conda-forge | (main, Nov 22 2022, 08:16:33) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1ae2ae2692dfc1c07e129644408a97e76237990466964fee524130ea11f1a816"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
